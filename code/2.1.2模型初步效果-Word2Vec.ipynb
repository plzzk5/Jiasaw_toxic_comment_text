{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86181\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.stem\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标点符号：\n",
    "remove = str.maketrans('','',string.punctuation)\n",
    "stemwords = nltk.stem.SnowballStemmer('english')\n",
    "def token(x):#字符清洗\n",
    "    remove = str.maketrans('','',string.punctuation)\n",
    "    x = x.lower()\n",
    "    x = re.sub('[\\d]','',x)\n",
    "    x = x.translate(remove)\n",
    "    cutwords = word_tokenize(x)\n",
    "    without_stopwords = [w for w in cutwords if not w in stopwords.words('english')]\n",
    "    cleaned_text = [stemwords.stem(w) for w in without_stopwords]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_W2V(data,name = 'W2V'):\n",
    "    model = Word2Vec(vector_size = 256,min_count = 10)\n",
    "    model.build_vocab(data)\n",
    "    model.train(data,total_examples = model.corpus_count,epochs =2)\n",
    "    model.save(name+'.model')\n",
    "    return model\n",
    "\n",
    "def get_sentence_vector(sentence_list,model):\n",
    "    n = len(sentence_list)\n",
    "    vector = np.zeros(256)\n",
    "    for i in sentence_list:\n",
    "        if i in model.wv.index_to_key:\n",
    "            vector = vector+model.wv[i]\n",
    "    vector = vector/n\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listStore(listname,filename):\n",
    "    a=np.array(listname)\n",
    "    np.save(filename+'.npy',a) \n",
    "    print('succeed!')\n",
    "    return\n",
    "\n",
    "def readlist(path):\n",
    "    a = np.load(path)\n",
    "    a = a.tolist()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputclean(X,Y):#将数据中的空值和无穷大值剔除\n",
    "    count = 0\n",
    "    index = []\n",
    "    n = len(X)\n",
    "    for i in range(n):\n",
    "        if np.isfinite(X[i]).all() == False or np.isnan(X[i]).all():\n",
    "            index.append(i)\n",
    "            count = count+1\n",
    "    for i in reversed(index):\n",
    "        del X[i]\n",
    "        del Y[i]\n",
    "    print(f'{count} sets of data have been dropped.')\n",
    "    return X,Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_train(train_vecs,y_train,test_vecs,y_test,name = 'model1'):\n",
    "    clf=SVC(kernel='rbf',verbose=True)\n",
    "    start = time.time()\n",
    "    clf.fit(train_vecs,y_train)\n",
    "    joblib.dump(clf, name+'.pkl')\n",
    "    duration = time.time()-start\n",
    "    print(f'duration: {duration}')\n",
    "    print(clf.score(test_vecs,y_test))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train(train_vecs,y_train,test_vecs,y_test,name = 'knn'):\n",
    "    knn = KNN(n_neighbors = 6)\n",
    "    start = time.time()\n",
    "    knn.fit(train_vecs,y_train)\n",
    "    duration = time.time()-start\n",
    "    \n",
    "    print(f\"training completed! duration:{duration}\")\n",
    "    \n",
    "    joblib.dump(knn,name+'.pkl')\n",
    "    \n",
    "    print(\"model saved!\")\n",
    "    \n",
    "    #pre = knn.predict(test_vecs)\n",
    "    #print(f'{accuracy_score(y_test,pre)}  duration:{duration}')\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对单个句子进行情感判断    \n",
    "def predict(string,wvmodel,premodel):\n",
    "    words=token(string)\n",
    "    words_vecs=get_sentence_vector(words,wvmodel)\n",
    "\n",
    "    result=premodel.predict([words_vecs])\n",
    "    \n",
    "    if int(result[0])==1:\n",
    "        print(string,' toxic')\n",
    "    else:\n",
    "        print(string,' non-toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_train['cleaned'] = df_train['comment_text'].apply(lambda x:token(x))\n",
    "df_train = df_train[['cleaned','toxic']]\n",
    "df_train.to_csv('train_cleaned.csv')\n",
    "x_train = df_train['cleaned']\n",
    "y_train = np.array(df_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "df_test['cleaned'] = df_test['comment_text'].apply(lambda x:token(x))\n",
    "df_test = df_test[['cleaned','toxic']]\n",
    "df_test.to_csv('test_cleaned.csv')\n",
    "x_test = df_test['cleaned']\n",
    "y_test = np.array(df_test['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = get_W2V(X)\n",
    "model = Word2Vec.load('W2V.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86181\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trVec = [get_sentence_vector(i,model) for i in x_train] #训练向量\n",
    "teVec = [get_sentence_vector(i,model) for i in x_test]  #测试向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed!\n",
      "succeed!\n"
     ]
    }
   ],
   "source": [
    "listStore(trVec,'trVec')\n",
    "listStore(teVec,'teVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed!\n",
      "succeed!\n"
     ]
    }
   ],
   "source": [
    "listStore(y_train,'ytr')\n",
    "listStore(y_test,'yte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从这里开始跑！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 sets of data have been dropped.\n",
      "7 sets of data have been dropped.\n"
     ]
    }
   ],
   "source": [
    "Y_tr = readlist('ytr.npy')\n",
    "X_tr = readlist('trVec.npy')\n",
    "X_te = readlist('teVec.npy')\n",
    "Y_te = readlist('yte.npy')\n",
    "X_tr,Y_tr = inputclean(X_tr,Y_tr)\n",
    "X_te,Y_te = inputclean(X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = X_tr[:10000]\n",
    "y_tr = Y_tr[:10000]\n",
    "x_te = X_te[:300]\n",
    "y_te = Y_te[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training completed! duration:2.188566207885742\n",
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "clf = knn_train(X_tr,Y_tr,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]duration: 6.59570837020874\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "svm = svm_train(x_tr,y_tr,x_te,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = clf.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you suck ,motherfucker  toxic\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"knn.pkl\")\n",
    "wvmodel = Word2Vec.load('W2V.model')\n",
    "test = 'you suck ,motherfucker'\n",
    "vec = get_sentence_vector(test,wvmodel)\n",
    "predict(test,wvmodel,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"sorry but you are still an asshole,you fuck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry but you are still an asshole,you fuck  toxic\n"
     ]
    }
   ],
   "source": [
    "predict(test,wvmodel,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCM(model,X_te,Y_te):#计算混淆矩阵\n",
    "    n00 = 0\n",
    "    n01 = 0\n",
    "    n10 = 0\n",
    "    n11 = 0\n",
    "    count = 0\n",
    "    n = len(X_te)\n",
    "    start = time.time()\n",
    "    for idx in range(n):\n",
    "        pre = model.predict([X_te[idx]])[0]\n",
    "        true = Y_te[idx]\n",
    "        if true == 0:\n",
    "            if pre ==0 :\n",
    "                n00 = n00+1\n",
    "            else:\n",
    "                n01 = n01+1\n",
    "        else:\n",
    "            if pre ==0:\n",
    "                n10 = n10+1\n",
    "            else:\n",
    "                n11 = n11+1\n",
    "        if idx<10:\n",
    "            print('\\r'+'■'*((idx*30)//n)+str(round(idx*100/n,2))+'%',end = '')\n",
    "        elif idx == 10:\n",
    "            timecost = time.time()-start\n",
    "            eta = (n-idx)/10*timecost\n",
    "            print('\\r'+'■'*((idx*30)//n)+str(round(idx*100/n,2))+'%'+' eta:'+str(round(eta,1))+'s',end = '')           \n",
    "        else :\n",
    "            eta = (n-idx)/10*timecost\n",
    "            print('\\r'+'■'*((idx*30)//n)+str(round(idx*100/n,2))+'%'+' eta:'+str(round(eta,1))+'s',end = '')\n",
    "    print('\\r'+'■'*30+'100%'+'completed!')\n",
    "    return n00,n01,n10,n11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■100%completed!s\n"
     ]
    }
   ],
   "source": [
    "n00,n01,n10,n11 = getCM(model,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8574660633484162\n",
      "presicion:0.9513422818791947\n",
      "recall:0.4491089108910891\n"
     ]
    }
   ],
   "source": [
    "n = n00+n01+n10+n11\n",
    "print(f'accuracy:{(n00+n11)/n}')\n",
    "print(f'presicion:{n11/(n01+n11)}')\n",
    "print(f'recall:{n11/(n10+n11)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59915"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble(决策树+adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier as EEC\n",
    "knnmodel = joblib.load('knn.pkl')\n",
    "ee = EEC(random_state=0,n_estimators = 10,base_estimator = knnmodel,warm_start = True)\n",
    "ee = ee.fit(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■100%completed!ss\n"
     ]
    }
   ],
   "source": [
    "n00,n01,n10,n11 = getCM(ee,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8589415699390124\n",
      "presicion:0.6677945247616118\n",
      "recall:0.8598019801980198\n"
     ]
    }
   ],
   "source": [
    "n = n00+n01+n10+n11\n",
    "print(f'accuracy:{(n00+n11)/n}')\n",
    "print(f'presicion:{n11/(n01+n11)}')\n",
    "print(f'recall:{n11/(n10+n11)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6561"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUSboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier as RUS\n",
    "rus = RUS(random_state = 0)\n",
    "rus = rus.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■100%completed!\n"
     ]
    }
   ],
   "source": [
    "n00,n01,n10,n11 = getCM(rus,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8719260279362581\n",
      "presicion:0.6993805021193349\n",
      "recall:0.8495049504950495\n"
     ]
    }
   ],
   "source": [
    "n = n00+n01+n10+n11\n",
    "print(f'accuracy:{(n00+n11)/n}')\n",
    "print(f'presicion:{n11/(n01+n11)}')\n",
    "print(f'recall:{n11/(n10+n11)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balancedbagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier as BBC\n",
    "bbc = BBC(warm_start = True)\n",
    "bbc = bbc.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■100%completed!\n"
     ]
    }
   ],
   "source": [
    "n00,n01,n10,n11 = getCM(bbc,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8819594727523117\n",
      "presicion:0.7694184627897519\n",
      "recall:0.7493069306930693\n"
     ]
    }
   ],
   "source": [
    "n = n00+n01+n10+n11\n",
    "print(f'accuracy:{(n00+n11)/n}')\n",
    "print(f'presicion:{n11/(n01+n11)}')\n",
    "print(f'recall:{n11/(n10+n11)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedrandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier as BRF\n",
    "brf = BRF(criterion = 'entropy')\n",
    "brf = brf.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■100%completed!\n"
     ]
    }
   ],
   "source": [
    "n00,n01,n10,n11 = getCM(brf,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8791068266771591\n",
      "presicion:0.7108002602472349\n",
      "recall:0.8653465346534653\n"
     ]
    }
   ],
   "source": [
    "n = n00+n01+n10+n11\n",
    "print(f'accuracy:{(n00+n11)/n}')\n",
    "print(f'presicion:{n11/(n01+n11)}')\n",
    "print(f'recall:{n11/(n10+n11)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  'a pair of jewhating weiner nazi schmucks'\n",
    "temp = get_sentence_vector(x,wvmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf.predict([temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
